{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright **`(c)`** 2023 Giovanni Squillero `<giovanni.squillero@polito.it>`  \n",
    "[`https://github.com/squillero/computational-intelligence`](https://github.com/squillero/computational-intelligence)  \n",
    "Free for personal or classroom use; see [`LICENSE.md`](https://github.com/squillero/computational-intelligence/blob/master/LICENSE.md) for details.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAB10\n",
    "\n",
    "Use reinforcement learning to devise a tic-tac-toe player.\n",
    "\n",
    "### Deadlines:\n",
    "\n",
    "* Submission: [Dies Natalis Solis Invicti](https://en.wikipedia.org/wiki/Sol_Invictus)\n",
    "* Reviews: [Befana](https://en.wikipedia.org/wiki/Befana)\n",
    "\n",
    "Notes:\n",
    "\n",
    "* Reviews will be assigned  on Monday, December 4\n",
    "* You need to commit in order to be selected as a reviewer (ie. better to commit an empty work than not to commit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import choice\n",
    "from itertools import permutations\n",
    "from more_itertools import unique_everseen\n",
    "from copy import deepcopy\n",
    "from numpy import base_repr\n",
    "from enum import Enum\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can model a Tic Tac Toe board as a magic square\n",
    "\n",
    "| 2 | 9 | 4 |\n",
    "|---|---|---|\n",
    "| **7** | **5** | **3** |\n",
    "| **6** | **1** | **8** |\n",
    "\n",
    "To win, a player must choose positions whose sum equals 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAGIC = [2, 9, 4, 7, 5, 3, 6, 1, 8]\n",
    "\n",
    "class Status(Enum):\n",
    "    ONGOING = 0\n",
    "    X_WINS = 1\n",
    "    O_WINS = 2\n",
    "    TIE = 3\n",
    "    INVALID = 4\n",
    "\n",
    "class Player(Enum):\n",
    "    NONE = 0\n",
    "    X = 1\n",
    "    O = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TicTacToe:\n",
    "\n",
    "\n",
    "    def __init__(self, *args) -> None:\n",
    "        \"\"\"Initialize a Tic-Tac-Toe board. If initialized using a list of integers, returns a board where the moves in the list are played in order. If initialized using a single integer, returns the board based on its unique representation (see __int__). Otherwise initializes an empty board.\"\"\"\n",
    "        if len(args) > 0 and isinstance(args[0], list):\n",
    "            moves = args[0]\n",
    "            self.x = {e for i, e in enumerate(moves) if i%2==0}\n",
    "            self.o = {e for i, e in enumerate(moves) if i%2==1}\n",
    "            self.available = {e for e in range(1, 10) if e not in moves}\n",
    "        elif len(args) > 0 and isinstance(args[0], int):\n",
    "            num = base_repr(args[0], 3).rjust(9, '0')  # ternary representation of the board, with leading zeros to length 9\n",
    "            self.available = {9 - i for i, e in enumerate(num) if e=='0'}     \n",
    "            self.x = {9 - i for i, e in enumerate(num) if e=='1'}\n",
    "            self.o = {9 - i for i, e in enumerate(num) if e=='2'}\n",
    "        else:\n",
    "            self.x = set()\n",
    "            self.o = set()\n",
    "            self.available = set(range(1, 10))\n",
    "\n",
    "\n",
    "    def __int__(self) -> int:\n",
    "        \"\"\"Represents the state of the board as a unique number\"\"\"\n",
    "        res = ''\n",
    "        for element in range(9, 0, -1):\n",
    "            if element in self.x:\n",
    "                res += '1'\n",
    "            elif element in self.o:\n",
    "                res += '2'\n",
    "            else:\n",
    "                res += '0'\n",
    "        return int(res, 3)\n",
    "\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        \"\"\"Returns a string used to display the board state\"\"\"\n",
    "        res = \"\"\n",
    "        for r in range(3):\n",
    "            for c in range(3):\n",
    "                i = 3 * r + c\n",
    "                if MAGIC[i] in self.x:\n",
    "                    res += \"x\"\n",
    "                elif MAGIC[i] in self.o:\n",
    "                    res += \"o\"\n",
    "                else:\n",
    "                    res += \"-\"\n",
    "            res += \"\\n\"\n",
    "        return res\n",
    "\n",
    "\n",
    "    def check_status(self):\n",
    "        \"\"\"Check if the game is terminated. A game is terminated if either player won, no more moves are available, or the state is invalid.\"\"\"\n",
    "        curr_status = Status.ONGOING\n",
    "        for t in permutations(self.x, 3):\n",
    "            if sum(t) == 15:\n",
    "                if curr_status==Status.ONGOING or curr_status==Status.X_WINS:\n",
    "                    curr_status = Status.X_WINS\n",
    "                else:\n",
    "                    curr_status = Status.INVALID\n",
    "                break\n",
    "        for t in permutations(self.o, 3):\n",
    "            if sum(t) == 15:\n",
    "                if curr_status==Status.ONGOING:\n",
    "                    curr_status = Status.O_WINS\n",
    "                else:\n",
    "                    curr_status = Status.INVALID\n",
    "                break\n",
    "        if curr_status == Status.ONGOING and not self.available:\n",
    "            curr_status = Status.TIE\n",
    "        return curr_status\n",
    "\n",
    "\n",
    "    def play(self, pos:int) -> None:\n",
    "        \"\"\"Plays a move in the board. pos is the position in the magic square corresponding to the move to be played. Returns True if the move was played, False otherwise.\"\"\"\n",
    "        if pos not in self.available:\n",
    "            return False\n",
    "        if len(self.available) % 2 == 1:\n",
    "            self.x.add(pos)\n",
    "        else:\n",
    "            self.o.add(pos)\n",
    "        self.available.remove(pos)\n",
    "        return True\n",
    "\n",
    "\n",
    "    def transform(self, sequence, revert=False):\n",
    "        \"\"\"Applies a sequence of transformations, defined as dictionaries {from: to} to the board. revert = True applies the inverse of the transformations in reverse order.\"\"\"\n",
    "        def apply_transformation(board:TicTacToe, map):\n",
    "            board.available = {map[element] for element in board.available}\n",
    "            board.x = {map[element] for element in board.x}\n",
    "            board.o = {map[element] for element in board.o}\n",
    "            \n",
    "        new = deepcopy(self)\n",
    "        if revert:\n",
    "            sequence = reversed(sequence)\n",
    "        for transformation in sequence:\n",
    "            if revert:\n",
    "                transformation = dict([(value, key) for key, value in transformation.items()])\n",
    "            apply_transformation(new, transformation)\n",
    "        return new\n",
    "\n",
    "\n",
    "    def canonize(self):\n",
    "        \"\"\"Return a canonical state equivalent to the current one and the sequence of transformations used to reach it\"\"\"\n",
    "        rotate = {  # clockwise 90° rotation of the board\n",
    "            1: 7,\n",
    "            2: 4,\n",
    "            3: 1,\n",
    "            4: 8,\n",
    "            5: 5,\n",
    "            6: 2,\n",
    "            7: 9,\n",
    "            8: 6,\n",
    "            9: 3\n",
    "        }\n",
    "        flip = {    # vertical flip\n",
    "            1: 9,\n",
    "            2: 6,\n",
    "            3: 3,\n",
    "            4: 8,\n",
    "            5: 5,\n",
    "            6: 2,\n",
    "            7: 7,\n",
    "            8: 4,\n",
    "            9: 1\n",
    "        }\n",
    "        equivalent = {self: list()}  # states that are equivalent to the current and the transformations used to reach them\n",
    "        representations = {int(self)} # set containing the representation of each state\n",
    "        morphs = [[flip], [rotate], [flip, rotate], [rotate, rotate], [flip, rotate, rotate], [rotate, rotate, rotate], [flip, rotate, rotate, rotate]]\n",
    "        for morph in morphs:\n",
    "            result = self.transform(morph)\n",
    "            if int(result) not in representations:\n",
    "                representations.add(int(result))\n",
    "                equivalent[result] = morph\n",
    "        return min(equivalent.items(), key = lambda e: int(e[0]))\n",
    "\n",
    "\n",
    "    def valid(self) -> bool:\n",
    "        \"\"\"Returns False if the state is invalid, True otherwise. A state is invalid if the difference between the number of x and os is greater than one, or if both players won\"\"\"\n",
    "        return len(self.x) - len(self.o) <= 1 and self.check_status() != Status.INVALID\n",
    "\n",
    "\n",
    "    def current_player(self) -> Player:\n",
    "        \"\"\"Returns the player that needs to make a move\"\"\"\n",
    "        return Player.X if len(self.available) % 2 == 1 else Player.O\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--x\n",
      "---\n",
      "---\n",
      "\n",
      "--x\n",
      "--o\n",
      "---\n",
      "\n",
      "-xx\n",
      "--o\n",
      "---\n",
      "\n",
      "-xx\n",
      "--o\n",
      "-o-\n",
      "\n",
      "xxx\n",
      "--o\n",
      "-o-\n",
      "\n",
      "X_WINS\n"
     ]
    }
   ],
   "source": [
    "def random_agent(board:TicTacToe):\n",
    "    \"\"\"Random agent: plays a random move from those available in the board\"\"\"\n",
    "    return choice(list(board.available))\n",
    "\n",
    "ttt = TicTacToe()\n",
    "status = Status.ONGOING\n",
    "while status == Status.ONGOING:\n",
    "    canon, morph = ttt.canonize()\n",
    "    canon.play(random_agent(canon))\n",
    "    ttt = canon.transform(morph, revert=True)\n",
    "    print(ttt)\n",
    "    status = ttt.check_status()\n",
    "print(Status(status).name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Markov Decision Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MDP:\n",
    "    def __init__(self, player = Player.X) -> None:\n",
    "        self.player = player\n",
    "        self.states = self.generate_states()\n",
    "        self.discount = 0.5\n",
    "\n",
    "\n",
    "    def generate_states(self):\n",
    "        \"\"\"Generates all possible states of a Tic-Tac-Toe board where it's the player's turn, applying symmetry and pruning to reduce them.\"\"\"\n",
    "        states = set()\n",
    "#        count = 1\n",
    "        start = 0 if self.player == Player.X else 1\n",
    "        for length in range(start, 9, 2):\n",
    "            perms = list(permutations(range(1, 10), length))\n",
    "#            count += len(perms)\n",
    "            for perm in unique_everseen(perms, key = lambda e: int(TicTacToe(list(e)))):  # remove equivalent boards\n",
    "                ttt, _ = TicTacToe(list(perm)).canonize()\n",
    "                if ttt.valid():\n",
    "                    states.add(int(ttt))\n",
    "#        print(\"Generated\", count, \"states,\", len(states), \"after pruning\")\n",
    "        return states\n",
    "\n",
    "\n",
    "    def reward(self, state):\n",
    "        \"\"\"Calculates the reward for the current state. Returns 0 if the state is non-terminal, 1 if the player wins, -1 if it loses, -0.5 if it's a draw\"\"\"\n",
    "        status = TicTacToe(state).check_status()\n",
    "        if status == Status.ONGOING:\n",
    "            return 0\n",
    "        elif status == Status.TIE:\n",
    "            return -0.5\n",
    "        elif (status == Status.X_WINS and self.player == Player.X) or (status == Status.O_WINS and self.player == Player.O):\n",
    "            return 1\n",
    "        return -1\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def transition_model(state, action):\n",
    "        \"\"\"Returns a list of tuples (state, prob) describing the probability of reaching a certain state after applying an action to the state\"\"\"\n",
    "        ttt = TicTacToe(state)\n",
    "        if ttt.check_status() != Status.ONGOING: # the state is terminal before the player moves\n",
    "            return [(int(ttt), 0)]\n",
    "        ttt.play(action)\n",
    "        if ttt.check_status() != Status.ONGOING: # the state is terminal after the player moves, but before the opponent does\n",
    "            return [(int(ttt.canonize()[0]), 1)]\n",
    "        probs = {}\n",
    "        for move in ttt.available:\n",
    "            tmp = deepcopy(ttt)\n",
    "            tmp.play(move)\n",
    "            tmp, _ = tmp.canonize()\n",
    "            if tmp.check_status() != Status.INVALID:\n",
    "                if int(tmp) not in probs.keys():\n",
    "                    probs[int(tmp)] = 0\n",
    "                probs[int(tmp)] += 1\n",
    "        return [(k, v/sum(probs.values())) for k, v in probs.items()]\n",
    "\n",
    "\n",
    "    def q_value(self, state, action, utilities):\n",
    "        \"\"\"Returns an utility value for the given action at the given state\"\"\"\n",
    "        possible_states = MDP.transition_model(state, action)\n",
    "        value = 0\n",
    "        for possible_state, probability in possible_states:\n",
    "            if TicTacToe(possible_state).check_status() != Status.ONGOING:\n",
    "                value += self.reward(possible_state)\n",
    "            else:\n",
    "                value += probability * (self.reward(possible_state) + self.discount * utilities[possible_state])\n",
    "        return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def value_iteration(mdp: MDP, eps = 0.0001):\n",
    "    \"\"\"Calculates the utility of each state. Returns a dictionary containing the best move for each state (policy).\"\"\"\n",
    "    def bellman_update(state, utilities):\n",
    "        res = list()\n",
    "        for action in TicTacToe(state).available:\n",
    "            res.append((action, mdp.q_value(state, action, utilities)))\n",
    "        if len(res) == 0:\n",
    "            return [(None, mdp.reward(state))]\n",
    "        return max(res, key = lambda e: e[1])\n",
    "    \n",
    "    utilities_prime = {state: 0 for state in mdp.states}\n",
    "    policy = {state: None for state in mdp.states}\n",
    "    epoch = 0\n",
    "    while True:\n",
    "        delta = 0\n",
    "        epoch += 1\n",
    "        utilities = utilities_prime.copy()\n",
    "        for state in tqdm(mdp.states):\n",
    "            policy[state], utilities_prime[state] = bellman_update(state, utilities)\n",
    "            delta = max(delta, abs(utilities_prime[state] - utilities[state]))\n",
    "        print(\"epoch\", epoch, \"delta =\", delta)\n",
    "        if delta <= eps * (1 - mdp.discount)/mdp.discount:\n",
    "            break\n",
    "    return policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 426/426 [00:00<00:00, 460.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 delta = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 426/426 [00:00<00:00, 458.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2 delta = 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 426/426 [00:00<00:00, 448.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3 delta = 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 426/426 [00:00<00:00, 447.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4 delta = 0.020182291666666685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 426/426 [00:00<00:00, 455.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5 delta = 0.00016276041666665741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 426/426 [00:00<00:00, 441.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6 delta = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "policy_x = value_iteration(MDP(player=Player.X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 383/383 [00:00<00:00, 435.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 delta = 2.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 383/383 [00:00<00:00, 445.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2 delta = 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 383/383 [00:00<00:00, 446.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3 delta = 0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 383/383 [00:00<00:00, 446.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4 delta = 0.01428571428571429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 383/383 [00:00<00:00, 433.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5 delta = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "policy_o = value_iteration(MDP(player=Player.O))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy_agent(policy, board:TicTacToe):\n",
    "    \"\"\"An agent that plays a move based on a policy\"\"\"\n",
    "    return policy[int(board)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [01:16<00:00, 1310.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Playing as X\n",
      "Win rate: 99.477 %\n",
      "Loss rate: 0.0 %\n",
      "Tie rate: 0.523 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def evaluate_policy(player, policy):\n",
    "    wins = 0\n",
    "    losses = 0\n",
    "    ties = 0\n",
    "    for _ in tqdm(range(100_000)):\n",
    "        ttt = TicTacToe()\n",
    "        status = Status.ONGOING\n",
    "        while status == Status.ONGOING:\n",
    "            if ttt.current_player() == player:\n",
    "                ttt, morph = ttt.canonize()\n",
    "                ttt.play(policy_agent(policy, ttt))\n",
    "                ttt = ttt.transform(morph, revert=True)\n",
    "            else:\n",
    "                ttt.play(random_agent(ttt))\n",
    "            status = ttt.check_status()\n",
    "        if (status == Status.X_WINS and player == Player.X) or (status == Status.O_WINS and player == player.O):\n",
    "            wins += 1\n",
    "        elif (status == Status.O_WINS and player == Player.X) or (status == Status.X_WINS and player == player.O):\n",
    "            losses += 1\n",
    "        else:\n",
    "            ties += 1\n",
    "    print(\"Playing as\", Player(player).name)\n",
    "    print(\"Win rate:\", wins/1_000, \"%\\nLoss rate:\", losses/1_000, \"%\\nTie rate:\", ties/1_000,\"%\")wins = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [01:22<00:00, 1218.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Playing as O\n",
      "Win rate: 91.637 %\n",
      "Loss rate: 0.0 %\n",
      "Tie rate: 8.363 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Value Iteration\")\n",
    "evaluate_policy(Player.X, policy_x)\n",
    "print()\n",
    "evaluate_policy(Player.O, policy_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy_iteration(mdp: MDP):\n",
    "    \"\"\"Iteratively calculates the policy\"\"\"\n",
    "    def policy_eval(policy, utilities):\n",
    "        for state in utilities.keys():\n",
    "            utilities[state] = mdp.q_value(state, policy[state], utilities)\n",
    "        return utilities\n",
    "    policy = {state: choice(list(TicTacToe(state).available)) for state in mdp.states}\n",
    "    utilities = {state: 0 for state in mdp.states}\n",
    "    epoch = 0\n",
    "    change = True\n",
    "    while change:\n",
    "        epoch += 1\n",
    "        utilities = policy_eval(policy, utilities)\n",
    "        change = False\n",
    "        for state in mdp.states:\n",
    "            best_action = None\n",
    "            best_value = None\n",
    "            for action in TicTacToe(state).available:\n",
    "                value = mdp.q_value(state, action, utilities)\n",
    "                if best_value is None or best_value < value:\n",
    "                    best_value = value\n",
    "                    best_action = action\n",
    "            if best_value > mdp.q_value(state, policy[state], utilities):\n",
    "                policy[state] = best_action\n",
    "                change = True\n",
    "    print(\"Policy found after\", epoch, \"epochs.\")\n",
    "    return policy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy found after 5 epochs.\n"
     ]
    }
   ],
   "source": [
    "policy_x = policy_iteration(mdp=MDP(player=Player.X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_o = policy_iteration(mdp=MDP(player=Player.O))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Policy Iteration\")\n",
    "evaluate_policy(Player.X, policy_x)\n",
    "print()\n",
    "evaluate_policy(Player.O, policy_o)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ci-fLJ3OwGs-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
